{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '../data/data_intermediaire.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Sea Is Watching has been made from an orig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are so many reasons as to why I rate the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The documentary presents an original theory ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Of all Arnold's mid-'80s movies who would have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Was One Scary Movie.&lt;br /&gt;&lt;br /&gt;Brad Pitt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>This may be one of the worst movies to ever ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>This is certainly the worst movie i ever saw? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>for all the subtle charms this student film ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Let's be honest shall we? Al Gore no more TRUL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I think they really let the quality of the DVD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      The Sea Is Watching has been made from an orig...      1\n",
       "1      There are so many reasons as to why I rate the...      1\n",
       "2      The documentary presents an original theory ab...      1\n",
       "3      Of all Arnold's mid-'80s movies who would have...      1\n",
       "4      This Was One Scary Movie.<br /><br />Brad Pitt...      1\n",
       "...                                                  ...    ...\n",
       "24995  This may be one of the worst movies to ever ma...      0\n",
       "24996  This is certainly the worst movie i ever saw? ...      0\n",
       "24997  for all the subtle charms this student film ma...      0\n",
       "24998  Let's be honest shall we? Al Gore no more TRUL...      0\n",
       "24999  I think they really let the quality of the DVD...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(input)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      2485\n",
      "           1       0.85      0.85      0.85      2515\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorisation du texte avec TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner un classificateur Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédire les étiquettes sur l'ensemble de test\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour Word2Vec\n",
    "sentences = df['text'].apply(gensim.utils.simple_preprocess).tolist()\n",
    "\n",
    "# Entraîner un modèle Word2Vec\n",
    "vector_size = 100\n",
    "window = 5\n",
    "min_count = 2\n",
    "workers = 4\n",
    "\n",
    "word2vec_model = Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count, workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir les vecteurs de mots moyens pour chaque revue\n",
    "def get_mean_word_vector(text, model):\n",
    "    words = gensim.utils.simple_preprocess(text)\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      2485\n",
      "           1       0.81      0.82      0.81      2515\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appliquer la fonction pour obtenir les vecteurs de caractéristiques\n",
    "df['word_vector'] = df['text'].apply(lambda x: get_mean_word_vector(x, word2vec_model))\n",
    "\n",
    "# Convertir les vecteurs en DataFrame\n",
    "vector_df = pd.DataFrame(df['word_vector'].tolist())\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector_df, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner un classificateur Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes sur l'ensemble de test\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Évaluer les performances du modèle\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres: {'classifier__C': 100, 'classifier__solver': 'liblinear'}\n",
      "Meilleur score de validation croisée: 0.81372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      2485\n",
      "           1       0.81      0.82      0.81      2515\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Fonction pour obtenir les vecteurs de mots moyens pour chaque revue\n",
    "def get_mean_word_vector(text, model):\n",
    "    words = gensim.utils.simple_preprocess(text)\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Entraîner un modèle Word2Vec avec des paramètres par défaut\n",
    "vector_size = 100\n",
    "window = 5\n",
    "min_count = 2\n",
    "workers = 4\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X = vector_df\n",
    "y = df['label']\n",
    "\n",
    "# Définir le pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Définir les paramètres à optimiser\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10, 100],  # Régularisation pour Logistic Regression\n",
    "    'classifier__solver': ['liblinear', 'lbfgs']  # Solvers pour Logistic Regression\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Effectuer la recherche de grille\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Afficher les meilleurs paramètres et le score\n",
    "print(\"Meilleurs paramètres:\", grid_search.best_params_)\n",
    "print(\"Meilleur score de validation croisée:\", grid_search.best_score_)\n",
    "\n",
    "# Évaluer le modèle sur l'ensemble de test avec les meilleurs paramètres\n",
    "best_model = grid_search.best_estimator_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
